# Uber Rides Data Cleaning and Transformation

This section describes how I approached the data cleaning and transformation of the Uber rides dataset, outlining the steps, logic, and code used throughout the analysis.

---

## Loading and Exploring the Data

To start, I imported the core Python libraries: `pandas` for data manipulation, `numpy` for numerical operations, and `seaborn` and `matplotlib` for visualizations. I read the NCR ride bookings CSV file using `pd.read_csv()`, then explored the dataset using `df.head()` and `df.info()` to understand the data types and identify missing values. I also used `df.isnull().sum()` to quickly summarize missing data across all columns.

---

## Handling Missing Data

I noticed missing values in features such as `Avg VTAT`, `Avg CTAT`, `Booking Value`, and several rating and reason columns. To manage these, I created a unified indicator called `reasonmissingflag` to mark rows with absent cancellation or incomplete reasons. For rides marked incomplete or cancelled where reasons were missing, I filled them with `"Unknown"` or `"Not Applicable"` depending on the context, ensuring the dataset remained consistent for downstream analysis.

---

## Consolidating Cancellation and Incomplete Reasons

The dataset had multiple columns tracking cancellation reasons from customers, drivers, and incomplete rides. To streamline the workflow, I wrote a custom function `choose_reason()` and applied it with `df.apply()`, selecting the appropriate reason based on ride status in each row. This allowed me to create a single column, `IncompleteRideReasonClean`, simplifying the analysis of ride cancellations and incompletions.

---

## Streamlining Columns and Naming

I dropped redundant intermediate columns and flags no longer needed, such as raw reason fields and booking identifiers, using `df.drop()`. I also re-labeled several columns for clarity, mapping the binary ride status into a new field, `RideStatus`, that clearly indicates `"Complete"` or `"Incomplete"` rides.

---

## Feature Engineering for Datetime and Categorical Variables

I standardized the date and time columns using `pd.to_datetime()`, then extracted useful features like booking hour and day of the week. I also defined time-of-day bins (morning, afternoon, evening, night) using a helper function applied to the hour feature. For categorical variables like vehicle type and reasons, I checked `.unique()` values, and where inconsistencies were present, I standardized the categories for cleaner analysis.

---

## Analysis, Aggregation, and Export

I frequently used `groupby`, `value_counts`, and summary statistics for aggregation and sanity checking. I visualized ride status distributions, incomplete reasons, turnaround times, and distance metrics using `seaborn` and `matplotlib`. Finally, I exported the cleaned, analytics-ready dataset to CSV for reporting and dashboarding.

---

## Functions and Key Methods Used

- `pd.read_csv()`, `df.head()`, `df.info()`, `df.isnull().sum()` for initial exploration.
- Custom `choose_reason()` function with `df.apply()`.
- `df.drop()`, `df.rename()` for column cleanup.
- `pd.to_datetime()`, `.unique()`, `.replace()` for datetime and categorical standardization.
- Feature creation (hour, day name, time-of-day binning).
- Aggregation via `groupby` and `value_counts()`.
- Visual summaries with `seaborn` and `matplotlib`.
- Dataset export with `df.to_csv()`.

---

## Summary

Throughout this workflow, I emphasized robust handling of missing values, consolidation of reason fields, effective feature engineering, categorical cleaning, and visual analytics. This prepared the Uber rides dataset for deep-dive reporting, insights generation, and BI dashboarding.
